{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/Documents/Coding/NLP/NLP_basics/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Initializing models...\n",
      "Training...\n",
      "Epoch 1 - Loss: 10.9604\n",
      "Epoch 2 - Loss: 0.0190\n",
      "Epoch 3 - Loss: 0.0045\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# üî• Use MPS if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# --------------------------\n",
    "# Encoder with MLP Projection\n",
    "# --------------------------\n",
    "class SimpleRetrieverEncoder(nn.Module):\n",
    "    def __init__(self, base_model=\"sentence-transformers/all-MiniLM-L6-v2\", proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = SentenceTransformer(base_model)\n",
    "        self.embedding_adapter = nn.Sequential(\n",
    "            nn.Linear(384, 384),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(384, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, proj_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, texts):\n",
    "        with torch.no_grad():\n",
    "            emb = self.encoder.encode(texts, convert_to_tensor=True)\n",
    "        emb = emb.to(next(self.projector.parameters()).device)\n",
    "        emb = self.embedding_adapter(emb)\n",
    "        return self.projector(emb)\n",
    "\n",
    "# --------------------------\n",
    "# Dataset + Loss\n",
    "# --------------------------\n",
    "class QCDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return item[\"question\"], item[\"context\"]\n",
    "\n",
    "def cosine_similarity_loss(q_embed, c_embed):\n",
    "    scores = F.cosine_similarity(q_embed, c_embed)\n",
    "    targets = torch.ones_like(scores)\n",
    "    return F.mse_loss(scores, targets)\n",
    "\n",
    "# --------------------------\n",
    "# Load and Train\n",
    "# --------------------------\n",
    "print(\"Loading data...\")\n",
    "dataset = load_dataset(\"neural-bridge/rag-dataset-12000\")\n",
    "train_data = dataset[\"train\"]\n",
    "train_loader = DataLoader(QCDataset(train_data), batch_size=32, shuffle=True)\n",
    "\n",
    "print(\"Initializing models...\")\n",
    "question_model = SimpleRetrieverEncoder().to(device)\n",
    "context_model = SimpleRetrieverEncoder().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(question_model.parameters()) + list(context_model.parameters()), lr=1e-4\n",
    ")\n",
    "\n",
    "print(\"Training...\")\n",
    "for epoch in range(10):\n",
    "    total_loss = 0.0\n",
    "    for questions, contexts in train_loader:\n",
    "        # Get question embeddings and context embeddings\n",
    "        q_embed = question_model(questions).to(device)\n",
    "        c_embed = context_model(contexts).to(device)\n",
    "\n",
    "        loss = cosine_similarity_loss(q_embed, c_embed)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding and saving context embeddings...\n",
      "Saved to: context_embeddings.npy and context_texts.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"Encoding and saving context embeddings...\")\n",
    "\n",
    "all_contexts = [item[\"context\"] for item in train_data]\n",
    "all_ids = [str(i) for i in range(len(all_contexts))]\n",
    "\n",
    "context_embeddings = []\n",
    "batch_size = 64\n",
    "for i in range(0, len(all_contexts), batch_size):\n",
    "    batch = all_contexts[i:i+batch_size]\n",
    "    with torch.no_grad():\n",
    "        emb = context_model(batch).cpu().numpy()\n",
    "        context_embeddings.append(emb)\n",
    "\n",
    "# Stack and save\n",
    "context_embeddings = np.vstack(context_embeddings)\n",
    "np.save(\"context_embeddings.npy\", context_embeddings)\n",
    "\n",
    "with open(\"context_texts.json\", \"w\") as f:\n",
    "    json.dump(all_contexts, f)\n",
    "\n",
    "print(\"Saved to: context_embeddings.npy and context_texts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-3 Retrieved Contexts:\n",
      "\n",
      "Rank 1 (Score: 0.9987): Export Regulations and Compliance\n",
      "Hansen, Fay, Business Credit\n",
      "U.S. export laws and regulations are far-reaching and have become more so in recent years. Even large, sophisticated U.S. companies with substantial resources and compliance programs occasionally run afoul of the law and face time-consuming investigations and significant fines. In December 2003, Sun Microsystems and two of its subsidiaries agreed to pay $291,000 in fines to settle charges involving illegal exports of computers to military end-users in China and Egypt. In the same month, Honeywell International paid a penalty to settle changes that it illegally exported chemicals to Mexico. In February of this year, Morton International and its French and Japanese affiliates agreed to pay a $647,500 penalty to settle charges in connection with the export and reexport of chemical compounds in violation of U.S. regulations.\n",
      "\"The export control regime of the United States is one of the most complex in the world,\" says Barry A. Pupkin, Partner, Squire, Sanders & Dempsey LLP, Washington, De. Exports are regulated under several different statutes, including the Export Administration Act, the Arms Export Control Act, the International Emergency Economic Powers Act and the Trading with the Enemy Act. \"At least ten federal government agencies are involved in export controls--issuing regulations, licenses and the like,\" he notes. \"Given the complexity of the regulatory regime it is important that U.S. exporters take seriously the enforcement of export control laws.\"\n",
      "Most U.S. export controls are administered by the Departments of Commerce and Treasury. The State Department regulates any product or technology considered a munitions item. The federal government can impose fines and suspend or revoke export privileges for any violation of export laws or regulations.\n",
      "\"U.S. exporters are required to comply with numerous regulation dealing with a wide range of topics,\" says Stephen D. Elison, a Partner in the Houston office of Gardere Wynne Sewell. \"The Office of Foreign Assets Control, for example, enforces regulations affecting commerce between U.S. persons and certain embargoed countries. Not only does the list of embargoed countries change from time to time, but also the specific actions prohibited to U.S. persons are not uniform among the sanctioned countries. Consequently, any activity remotely connected to an embargoed country or national thereof must bc highly scrutinized to be certain that proper licensees have been obtained and that no U.S. person will be in violation of U.S. laws.\"\n",
      "Common Violations\n",
      "When assessed by the number of U.S. enforcement actions, the most common violations of export laws and regulations are direct and indirect shipments of equipment to embargoed destinations such as Cuba, Iran, Libya and Sudan. \"For major multinationals, the most difficult compliance challenge is probably U.S. restrictions on 'deemed exports' of controlled software and technology to foreign nationals in the United States and 'deemed reexports' of software and technology within foreign countries,\" says Harry L. Clark, Partner in the International Trade Group of international law firm Dewey Ballantine LLP, Washington, DC.\n",
      "Deemed export and deemed reexport controls are a particular challenge, even for large U.S. companies with experienced staff. \"These restrictions impose a license requirement for releases of certain software and technology to foreign nationals other than permanent residents, even if the software or technology never crosses a national border,\" Clark reports. The transfer is \"deemed\" to be an export to the home country of the foreign national. \"Deemed export/reexport controls are of most concern to technology-intensive firms in, for example, the microelectronics and computer sectors, such as Intel and IBM,\" he says. IBM maintains an extensive section on its web site to guide IBM partners through export compliance.\n",
      "\"Technology is 'released' for export when it is available to foreign nationals for visual inspection, such as reading technical specifications, plans or blueprints; is communicated orally; or is made available by practice or applications\" Pupkin explains. ‚Ä¶\n",
      "\n",
      "Rank 2 (Score: 0.9987): Location: London / Belfast\n",
      "FEATURE FILM EXPERIENCE:\n",
      "‚Äò Ali and Nino‚Äô ‚Äì Sound Assistant / Second Unit Sound Mixer.\n",
      "Sony Pictures Entertainment ‚Äì ‚ÄòGrimsby‚Äô- Second Boom.\n",
      "Fox UK ‚Äì ‚ÄòFrankenstein‚Äô ‚Äì Sound Assistant / Second Boom / Playback Operator.\n",
      "Working Title ‚Äì ‚Äò The Theory of Everything‚Äô ‚Äì First Sound Assistant / Second Boom / Playback Operator.\n",
      "Big Book Media ‚Äì ‚ÄòThe Christmas Candle‚Äô ‚Äì Sound Assistant / Second Boom.\n",
      "Working Title ‚Äì ‚ÄòThe Worlds End‚Äô- Sound Assistant / Second Boom.\n",
      "Archer Street Productions ‚Äì ‚ÄòThe Railway Man‚Äô ‚Äì Sound Assistant.\n",
      "Welpark Scotland ‚Äì ‚ÄòJig‚Äô World Irish Dancing Championships (Scottish BAFTA nominated Documentary) ‚Äì Sound Technician / Boom Operator /Mixer.\n",
      "Generator Entertainment Ltd ‚Äì ‚ÄòFreak Dog‚Äô /‚Äô Red Mist‚Äô ‚Äì Sound Assistant.\n",
      "Playtone/Walden Media ‚Äì ‚ÄòCity of Ember‚Äô ‚Äì Sound Assistant.\n",
      "TV DRAMA EXPERIENCE:\n",
      "‚Äì\n",
      "ITV -‚Äò Shetland ‚Äò ‚Äì Sound Assistant.\n",
      "Mammoth Screen (NI) ‚Äì BBC ‚ÄòPrimetime‚Äô ‚Äì Boom Operator.\n",
      "Ruby Films ‚Äì BBC ‚ÄòCase Histories‚Äô (Winner, Best Drama, Scottish BAFTA) ‚Äì Sound Assistant.\n",
      "BBC ‚Äì BBC ‚ÄòCranford II‚Äô (BAFTA, nominated for Best Sound)- Sound Assistant/Second Boom.\n",
      "BBC Productions ‚Äì ‚ÄòThe 39 Steps‚Äô ‚Äì Sound Assistant / Second Boom.\n",
      "BBC Scotland ‚Äì ‚ÄòSea of Souls‚Äô ‚Äì Sound Trainee.\n",
      "‚Äì\n",
      "QUALIFICATIONS:\n",
      "‚Äì\n",
      "2000-2003: BA HONS Film Studies/Sociology 2:1 Queens University Belfast\n",
      "2003-2005: Higher National Diploma Television Operations & Production Glasgow Clyde College\n",
      "‚Äì\n",
      "TRAINING/SHORT COURSES:\n",
      "‚Äì\n",
      "Oct 2013: NFTS: Location Sound Recording Short Course (five day course).\n",
      "June 2010: Waterfront Hall, Belfast: Urban Arts Academy: Stage Production (weekend course).\n",
      "June 2010: London Film School, London: Location Sound Recording (weekend course).\n",
      "March 2010: Digital Art Studio, Belfast: Audio Production Course, Logic Pro (evening course).\n",
      "May 2009: Alchemea College of Audio Engineering, London: Sound Mixing Techniques Masterclass: (Music-theory based weekend course.\n",
      "T : +44 797 212 9854\n",
      "E : creative@reelangels.tv\n",
      "\n",
      "Rank 3 (Score: 0.9986): The Most Toxic Towns in Rhode Island\n",
      "Thursday, April 12, 2012\n",
      "Much of the locally based pollution sources are old landfills, textile mills, industrial buildings, and other hazardous waste sites that were contaminated before modern environmental laws took effect, according to Eugenia Marks, Senior Director for Policy at the Audubon Society of Rhode Island. (See below for the complete breakdown.)\n",
      "The turning point for environmental regulation was four decades ago‚Äîin the early 1970s, when the landmark Clean Water Act and Clean Air Act were passed, along with a slew of other environmental reforms. Rhode Island, along with the rest of the country, has come a long way since then, but it is still paying the price for the sins of the past, Marks said.\n",
      "GoLocalProv examined five local sources of potential toxic pollution: hazardous waste sites, active and closed landfills; leaking underground storage tanks; businesses like incinerators and chemical manufacturing plants that produce toxic chemicals; and businesses that have a permit to release bacteria and toxic chemicals into waterways within certain limits. Data for each was culled from various databases maintained by the state DEM, the EPA, and other sources. (See below for more information.)\n",
      "The Communities at the Top\n",
      "The communities with the highest concentration of toxic pollution sources are also the most urbanized areas of the state. Central Falls found itself at the top of the list, followed by Providence, Pawtucket, and Woonsocket. But there are notable exception of rural communities that neared the top of the list, including Warren and Middletown.\n",
      "It‚Äôs no coincidence, she said, that higher rates of diseases like diabetes and asthma are also concentrated in the same places.\n",
      "‚ÄúWe know that health and environment go hand in hand,‚Äù Rose said. ‚ÄúThat‚Äôs why it‚Äôs so important that protections be put in place so that every community can enjoy a healthy environment.‚Äù\n",
      "But toxic sites aren‚Äôt concentrated in the cities only. Rose, a former state organizer for the Toxics Action Center, said toxic sites line some of the state‚Äôs water bodies, reflecting a historic use of water by textile mills. The mills may no longer be running, but businesses like wastewater treatment plants and boat yards to be closer to the water. And in Providence, the scrap metal businesses along Allens Avenue are one of the major potential sources of pollution in the city, according to environmental advocates.\n",
      "Pollution Sites: What is the risk?\n",
      "The toxic sites listed below pose varying risks to public health and the environment.\n",
      "‚ÄúWe have a lot of risks in life and this is one of them,‚Äù Rose said. ‚ÄúIt is something to be concerned about.‚Äù\n",
      "But even if an accident occurs or a rule occurs at one of the toxic sites, the level of risk to the public can only be assessed by determining on a case by case basis how people would become exposed to the toxic chemicals, according to John Torgan, director of ocean and coastal conservation at the state chapter of the Nature Conservancy. ‚ÄúJust the presence of toxic substances doesn‚Äôt mean there‚Äôs a public health risk,‚Äù Torgan said.\n",
      "Toxic Tanks to Lethal Landfills\n",
      "Sources of toxic chemicals range from leaking underground storage tanks hidden from view to that eyesore of an old landfill. Below are the five categories of toxic sites reviewed in the GoLocalProv toxic towns ranking:\n",
      "‚ñ† Businesses that produce or release toxic chemicals: These are businesses that are in the national Toxics Release Inventory, also maintained by the EPA. The database tracks businesses‚Äîwhich are required to report such things‚Äîthat use, manufacture, treat, transport, or release 650 various toxic chemicals. The category is far broader than the water dischargers and includes potential pollution from air emissions, releases into the ground, and underground injections as well as surface water discharges. The inventory can be accessed online here.\n",
      "‚ñ† Superfund sites: Since the 1970s, the word ‚ÄúSuperfund‚Äù has become virtually synonymous with hazardous waste sites, although the term technically refers to sites that have been identified as serious enough to warrant the EPA getting involved to clean them up and find those responsible for the contamination. There are degrees of seriousness‚Äîthe most toxic Superfund sites are on the National Priorities List. As of 2008, there were a dozen NPL Superfund sites in Rhode Island‚Äîwithin three miles of more than 115,000 residents, according to the Toxics Action Center. But the total number of all Superfund sites is currently just shy of 150. Click here to view the EPA database.\n",
      "‚ñ† Leaking underground storage tanks: Known as LUSTs, these hidden dangers are most commonly associated with gas stations. It wasn‚Äôt until the 1980s that the country woke up the hazards of broken and poorly insulated tanks contaminating the surround environment. According to the last count by DEM, there were approximately 1,700 LUSTs in Rhode Island as of 2006. The state has a fund to help businesses repair or upgrade their tanks, but the review commission that reviews businesses applications has a $1 million backlog, according to Paul Beaudette, one of the members. The threat of contamination from an underground storage tank is very much a real one: in the early 2000s, a leaky tank at a gas station in Burrillville released toxic BTEs in the aquifer which served as the drinking water for residents. (BTE stands for benzene, toluene, and ethylbenzene compounds.)\n",
      "If you valued this article, please LIKE GoLocalProv.com on Facebook by clicking HERE.\n",
      "Related Articles\n",
      "- The Top 20 Biggest Polluters in RI\n",
      "- Rhode Island‚Äôs Most Polluted Lakes\n",
      "- Using Pollution to Make Clean Energy\n",
      "- Accused Polluter Contributes Thousands to Top RI Politicians\n",
      "Follow us on Pinterest Google + Facebook Twitter See It Read It Share It\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load saved data\n",
    "embeddings = np.load(\"context_embeddings.npy\")\n",
    "with open(\"context_texts.json\") as f:\n",
    "    context_texts = json.load(f)\n",
    "\n",
    "# Encode the query\n",
    "query = \"What is the Berry Export Summary 2028 and what is its purpose?\"\n",
    "with torch.no_grad():\n",
    "    query_embedding = question_model([query]).cpu().numpy()\n",
    "\n",
    "# Compute cosine similarity\n",
    "sims = cosine_similarity(query_embedding, embeddings)[0]\n",
    "top_k_indices = sims.argsort()[::-1][:3]\n",
    "\n",
    "print(\"\\nTop-3 Retrieved Contexts:\")\n",
    "for i, idx in enumerate(top_k_indices):\n",
    "    print(f\"\\nRank {i+1} (Score: {sims[idx]:.4f}): {context_texts[idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
